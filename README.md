ðŸš« Toxic Comment Classifier Chrome Extension

The Toxic Comment Classifier is a Chrome Extension that uses machine learning or a pre-trained AI model to detect and flag toxic, rude, or abusive language in web comments, chat boxes, and social media posts in real time. It enhances your online experience by identifying harmful content before you interact with it.

Download Model - https://drive.google.com/file/d/1UKZCTnTLaRNr5FwrXLVeJLiPsBwZfCzt/view?usp=sharing
and paste into backend/bert_toxicity_model/tf_model.h5 

Change model and tokenizer path in app.py
